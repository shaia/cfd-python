name: Build and Test Wheels

on:
  push:
    branches: [main, master]
  pull_request:
  workflow_dispatch:
  workflow_call:

env:
  # CFD C library version to build against
  # v0.1.6 introduces modular backend libraries
  CFD_VERSION: "v0.1.6"

jobs:
  build_wheel:
    name: Build ${{ matrix.variant }} wheel on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        variant: [cpu, cuda]
        exclude:
          # macOS doesn't support CUDA
          - os: macos-latest
            variant: cuda

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout CFD C library
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository_owner }}/cfd
          ref: ${{ env.CFD_VERSION }}
          path: cfd
          fetch-depth: 0

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: "3.9"

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"

      - name: Install build dependencies
        run: uv pip install --system build scikit-build-core setuptools-scm

      # ============ CPU-only builds ============
      - name: Build CFD library (Linux - CPU only)
        if: runner.os == 'Linux' && matrix.variant == 'cpu'
        run: |
          # Build CPU-only for maximum compatibility
          # Includes: Scalar, SIMD (AVX2), OpenMP backends
          # Excludes: CUDA (avoid runtime dependency issues)
          cmake -S cfd -B cfd/build \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_SHARED_LIBS=OFF \
            -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
            -DCFD_ENABLE_CUDA=OFF
          cmake --build cfd/build --config Release
          echo "=== CFD library built (CPU-only) ==="
          ls -la cfd/build/lib/

      - name: Build CFD library (macOS - CPU only)
        if: runner.os == 'macOS'
        run: |
          cmake -S cfd -B cfd/build \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_SHARED_LIBS=OFF \
            -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
            -DCFD_ENABLE_CUDA=OFF
          cmake --build cfd/build --config Release
          echo "=== CFD library built (CPU-only) ==="
          ls -la cfd/build/lib/

      - name: Build CFD library (Windows - CPU only)
        if: runner.os == 'Windows' && matrix.variant == 'cpu'
        run: |
          # Build CPU-only for maximum compatibility
          cmake -S cfd -B cfd/build `
            -DCMAKE_BUILD_TYPE=Release `
            -DBUILD_SHARED_LIBS=OFF `
            -DCMAKE_POSITION_INDEPENDENT_CODE=ON `
            -DCFD_ENABLE_CUDA=OFF
          cmake --build cfd/build --config Release
          echo "=== CFD library built (CPU-only) ==="
          dir cfd\build\lib\Release

      # ============ CUDA builds ============
      - name: Install CUDA Toolkit (Linux)
        if: runner.os == 'Linux' && matrix.variant == 'cuda'
        uses: Jimver/cuda-toolkit@v0.2.18
        with:
          cuda: '12.6.2'
          method: 'network'
          sub-packages: '["nvcc", "cudart"]'

      - name: Build CFD library (Linux with CUDA)
        if: runner.os == 'Linux' && matrix.variant == 'cuda'
        run: |
          # Build with CUDA for Turing+ architectures (RTX 20 series onwards)
          # 75=Turing, 80=Ampere, 86=Ampere, 89=Ada, 90=Hopper
          cmake -S cfd -B cfd/build \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_SHARED_LIBS=OFF \
            -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
            -DCFD_ENABLE_CUDA=ON \
            -DCFD_CUDA_ARCHITECTURES="75;80;86;89;90"
          cmake --build cfd/build --config Release
          echo "=== CFD library built with CUDA ==="
          ls -la cfd/build/lib/

      - name: Install CUDA Toolkit (Windows)
        if: runner.os == 'Windows' && matrix.variant == 'cuda'
        uses: Jimver/cuda-toolkit@v0.2.18
        with:
          cuda: '12.6.2'
          method: 'network'
          sub-packages: '["nvcc", "cudart", "visual_studio_integration"]'

      - name: Build CFD library (Windows with CUDA)
        if: runner.os == 'Windows' && matrix.variant == 'cuda'
        run: |
          # Build with CUDA for Turing+ architectures
          cmake -S cfd -B cfd/build `
            -DCMAKE_BUILD_TYPE=Release `
            -DBUILD_SHARED_LIBS=OFF `
            -DCMAKE_POSITION_INDEPENDENT_CODE=ON `
            -DCFD_ENABLE_CUDA=ON `
            -DCFD_CUDA_ARCHITECTURES="75;80;86;89;90"
          cmake --build cfd/build --config Release
          echo "=== CFD library built with CUDA ==="
          dir cfd\build\lib\Release

      # ============ Build wheels ============
      - name: Build wheel (Unix)
        if: runner.os != 'Windows'
        env:
          CFD_ROOT: ${{ github.workspace }}/cfd
          CFD_STATIC_LINK: "ON"
          CFD_USE_STABLE_ABI: "ON"
        run: |
          pip wheel . --no-deps --wheel-dir dist/
          echo "=== Wheel built ==="
          ls -la dist/

      - name: Build wheel (Windows)
        if: runner.os == 'Windows'
        env:
          CFD_ROOT: ${{ github.workspace }}/cfd
          CFD_STATIC_LINK: "ON"
          CFD_USE_STABLE_ABI: "ON"
        run: |
          pip wheel . --no-deps --wheel-dir dist/
          echo "=== Wheel built ==="
          dir dist

      - name: Rename wheel for variant
        shell: bash
        run: |
          # Rename wheel to include variant suffix (cpu or cuda)
          for wheel in dist/*.whl; do
            if [ -f "$wheel" ]; then
              # Extract parts: name-version-pyver-abi-platform.whl
              basename=$(basename "$wheel" .whl)
              # Insert variant before platform tag
              # e.g., cfd_python-0.1.0-cp39-cp39-linux_x86_64.whl
              # becomes cfd_python-0.1.0-cp39-cp39-linux_x86_64+${{ matrix.variant }}.whl
              newname="${basename}+${{ matrix.variant }}.whl"
              mv "$wheel" "dist/$newname"
              echo "Renamed to: $newname"
            fi
          done
          ls -la dist/

      - name: Inspect wheel contents
        run: |
          python -c "
          import glob, zipfile
          for wheel in glob.glob('dist/*.whl'):
              print(f'=== Contents of {wheel} ===')
              with zipfile.ZipFile(wheel) as zf:
                  for name in zf.namelist():
                      print(name)
          "

      - uses: actions/upload-artifact@v4
        with:
          name: wheel-${{ matrix.os }}-${{ matrix.variant }}
          path: dist/*.whl

  test_wheel:
    name: Test ${{ matrix.variant }} wheel on ${{ matrix.os }} with Python ${{ matrix.python }}
    needs: [build_wheel]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python: ["3.9", "3.13"]
        variant: [cpu, cuda]
        exclude:
          # macOS doesn't have CUDA wheels
          - os: macos-latest
            variant: cuda

    steps:
      - name: Set up Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ matrix.python }}"

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: ""

      # Install CUDA runtime for CUDA wheel tests
      - name: Install CUDA Toolkit (Linux - for testing)
        if: runner.os == 'Linux' && matrix.variant == 'cuda'
        uses: Jimver/cuda-toolkit@v0.2.18
        with:
          cuda: '12.6.2'
          method: 'network'
          sub-packages: '["cudart"]'  # Only runtime, not nvcc

      - name: Install CUDA Toolkit (Windows - for testing)
        if: runner.os == 'Windows' && matrix.variant == 'cuda'
        uses: Jimver/cuda-toolkit@v0.2.18
        with:
          cuda: '12.6.2'
          method: 'network'
          sub-packages: '["cudart"]'

      - uses: actions/download-artifact@v4
        with:
          name: wheel-${{ matrix.os }}-${{ matrix.variant }}
          path: dist

      - name: Install wheel (Unix)
        if: runner.os != 'Windows'
        run: |
          python -m pip install dist/*.whl
          python -m pip install pytest numpy

      - name: Install wheel (Windows)
        if: runner.os == 'Windows'
        run: |
          python -m pip install (Get-ChildItem dist/*.whl).FullName
          python -m pip install pytest numpy

      - name: Test import (Unix)
        if: runner.os != 'Windows'
        run: |
          cd /tmp
          python -c "
          import cfd_python
          print('Package loaded:', cfd_python.__file__)
          print('Version:', cfd_python.__version__)
          print('Has list_solvers:', hasattr(cfd_python, 'list_solvers'))
          if hasattr(cfd_python, 'list_solvers'):
              print('Solvers:', cfd_python.list_solvers())
          "

      - name: Test import (Windows)
        if: runner.os == 'Windows'
        run: |
          cd $env:TEMP
          python -c "import cfd_python; print('Package loaded:', cfd_python.__file__); print('Version:', cfd_python.__version__); print('Has list_solvers:', hasattr(cfd_python, 'list_solvers')); print('Solvers:', cfd_python.list_solvers()) if hasattr(cfd_python, 'list_solvers') else None"

      - uses: actions/checkout@v4
        with:
          sparse-checkout: tests
          sparse-checkout-cone-mode: false

      - name: Run tests (Unix)
        if: runner.os != 'Windows'
        run: |
          cd /tmp
          pytest $GITHUB_WORKSPACE/tests/ -v

      - name: Run tests (Windows)
        if: runner.os == 'Windows'
        run: |
          cd $env:TEMP
          pytest "$env:GITHUB_WORKSPACE\tests" -v
